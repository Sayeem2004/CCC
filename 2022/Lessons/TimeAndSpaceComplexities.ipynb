{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time And Space Complexities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit Review\n",
    "\n",
    "Limits are an essential concept to understanding time and space complexities, so lets start with a review of them. If you are a sophomore or freshman and haven't learned limits yet, that is also fine. Time and space complexities mostly deal with basic limits that we can teach you within a couple minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does $\\lim_{n \\to \\infty}{\\frac{1}{n}}$ mean?\n",
    "\n",
    "This mathematical expression is asking to what value does $\\frac{1}{n}$ approach as $n$ approaches $\\infty$.\n",
    "\n",
    "We can figure this out intuitively by just plugging in increasingly large values of n to the expression. \n",
    "\n",
    "| N         | $\\frac{1}{n}$ | \n",
    "| :-        | :-            | \n",
    "| 10        | 0.1           | \n",
    "| 100       | 0.01          | \n",
    "| 1,000     | 0.001         | \n",
    "| 10,000    | 0.0001        |  \n",
    "| 100,000   | 0.00001       |  \n",
    "| 1,000,000 | 0.000001      | \n",
    "\n",
    "From these values that we have tested out, it appears that as $n$ gets larger and larger $\\frac{1}{n}$ gets smaller and smaller. $\\frac{1}{n}$ gets closer and closer to 0, but does not go past it as $n$ approaches $\\infty$, so we say that the $\\lim_{n \\to \\infty}{\\frac{1}{n}} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try a limit with some different variables.\n",
    "\n",
    "What is $\\lim_{x \\to n}{\\frac{1}{x}}$?\n",
    "\n",
    "This is the same type of limit as the example above, but the value we are approaching is unknown. We may guess and say this is also $0$ since it is the same form as below, but if we plug in $n = 100$, we see that the limit approaches $\\frac{1}{100}$ instead of $0$. Since the limit can change dependent on the value of $n$, we say this limit approaches $\\frac{1}{n}$ instead of a specific value. We just generalized the limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now probably the most important thing to realize about limits is that only the most significant term matters, lets see an example of this to fully understand what this means. \n",
    "\n",
    "What is $\\lim_{x \\to n}{3x^2 + x}$? Lets test out a couple values of increasingly large $n$.\n",
    "\n",
    "| N       | Expansion                | Value          |  \n",
    "| :-      | :-                       | :-             |\n",
    "| 10      | 300 + 10                 | 310            |\n",
    "| 100     | 10,000 + 100             | 30,100         |\n",
    "| 1,000   | 3,000,000 + 1,000        | 3,001,000      |\n",
    "| 10,000  | 300,000,000 + 10,000     | 300,010,000    |\n",
    "| 100,000 | 30,000,000,000 + 100,000 | 30,000,100,000 |\n",
    "\n",
    "As $n$ gets larger and larger the $x$ term becomes much less significant than the $x^2$ term. So when solving this limit we remove the $x$ term. $\\lim_{x \\to n}{3x^2 + x} = 3n^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Oh Notation\n",
    "\n",
    "Big Oh notation basically means to take the limit of the expression as the variables approaches $\\infty$, however there is a slight difference between limits and Big Oh notation. Lets take a look at an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lim_{x \\to n}{3x^2 + x} = 3n^3$\n",
    "\n",
    "$\\mathcal{O}(3n^2 + n) = n^2$ \n",
    "\n",
    "From this example, we can see that Big Oh notation, removes the coefficient (or constant factor) of the limit that we get. \n",
    "\n",
    "So why is this? \n",
    "\n",
    "Well it is because removing the constant factor helps us generalize algorithms better. Constants factor can be literally any number less than $\\infty$. Instead of saying these two algorithms belong to $\\mathcal{O}(2n)$, while these other two algorithms belong to $\\mathcal{O}(3n)$, it is easier to say that all four algorithms belong to $\\mathcal{O}(n)$. So when discussing Big Oh notation there should be no constant factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the most commonly used Big Oh notations from smallest to largest. \n",
    "\n",
    "| Big Oh Notation         | Specification | Name         | Doubling Factor                               |\n",
    "| :-:                     | :-:           | :-:          | :-:                                           |\n",
    "| $\\mathcal{O}(1)$        | $1$           | Constant     | $1$                                           |\n",
    "| $\\mathcal{O}(\\log{n})$  | $\\log_2{n}$   | Logarithmic  | $1 + \\frac{1}{\\log_2{n}} \\approx 1$           |\n",
    "| $\\mathcal{O}(\\sqrt{n})$ | $\\sqrt[2]{n}$ | Square Root  | $\\sqrt{2}$                                    |\n",
    "| $\\mathcal{O}(n)$        | $n$           | Linear       | $2$                                           |\n",
    "| $\\mathcal{O}(n\\log{n})$ | $n\\log_2{n}$  | Linearithmic | $2 + \\frac{2}{\\log_2{n}} \\approx 2$           |\n",
    "| $\\mathcal{O}(n^2)$      | $n^2$         | Quadratic    | $4$                                           |\n",
    "| $\\mathcal{O}(n^3)$      | $n^3$         | Cubic        | $8$                                           |\n",
    "| $\\mathcal{O}(2^n)$      | $2^n$         | Exponential  | $2^n$                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you may notice something unfamiliar in the table above. What in the world is a doubling factor?\n",
    "\n",
    "A doubling factor is something that is helpful in experimentally determing time and space complexities. Theoretically you can acheive them by solving the expression for $2n$ and $n$, and then dividing, as shown below.\n",
    "\n",
    "$\\mathcal{O}(n^2) \\rightarrow \\frac{x^2|_{2n}}{x^2|_{n}} \\rightarrow \\frac{(2n)^2}{(n)^2} \\rightarrow \\frac{4n^2}{n^2} \\rightarrow 4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets say we have an algorithm and we test it for increasing large values of n, as shown below.\n",
    "\n",
    "| N       | Run Time   | Space Used |\n",
    "| :-      | :-         | :-         |\n",
    "| 1,000   | 1 ms       | 1 kb       |\n",
    "| 2,000   | 4 ms       | 1 kb       |\n",
    "| 4,000   | 15 ms      | 1 kb       |\n",
    "| 8,000   | 66 ms      | 1 kb       |\n",
    "| 16,000  | 240 ms     | 1 kb       |\n",
    "| 32,000  | 955 ms     | 1 kb       |\n",
    "| 64,000  | 3,912 ms   | 1 kb       |\n",
    "| 128,000 | 16,343 ms  | 1 kb       |\n",
    "| 256,000 | 65,045 ms  | 1 kb       |\n",
    "| 512,000 | 246,656 ms | 1 kb.      |\n",
    "\n",
    "From looking at the run times we see that this algorithm has a doubling factor for time complexity of around 4, which means that it is $\\mathcal{O}(n^2)$. \n",
    "\n",
    "From looking at the space used we see that this algorithm has a doubling factor for space complexity of 1, which means that it is $\\mathcal{O}(1)$.\n",
    "\n",
    "However, it is important to remember that in competitive programming, we are mostly gonna find time complexities from looking at the code itself not from running it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity From Code\n",
    "\n",
    "The main way to figure out the time complexity of an algorithm from its code is to multiply the time complexities of nested parts of the code, and figuring out the most significant one. This process is illustrated below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(n):\n",
    "    for i in range(n):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we loop at the code for function1 line by line, we see that the for loop is $\\mathcal{O}(n)$. This is because the for loop goes from 0 to N-1, which is N terms. The print statement in $\\mathcal{O}(1)$, it is known to be that. The print statement is nested inside the for loop, so you multiple the two complexities to find the total complexity of the function. You can multiply the insides of the Big Oh notation normally, so this would be $\\mathcal{O}(n) \\cdot \\mathcal{O}(1) = \\mathcal{O}(n)$. So the total time complexity would be $\\mathcal{O}(n)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(n):\n",
    "    for i in range(n):\n",
    "        for q in range(n):\n",
    "            print(i)\n",
    "    for i in range(n):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In function2, we have two main parts of code the first double nested for loop and the second single for loop. We solve for the time complexities of each of these parts separately. The double nested for loop is $\\mathcal{O}(n) \\cdot \\mathcal{O}(n) \\cdot \\mathcal{O}(1) = \\mathcal{O}(n^2)$. The single loop is $\\mathcal{O}(n) \\cdot \\mathcal{O}(1) = \\mathcal{O}(n)$. Out of the two parts $\\mathcal{O}(n^2)$ is more significant than $\\mathcal{O}(n)$, so the total time complexity is $\\mathcal{O}(n^2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for some harder examples from actual algorithms you might learn later in the year, you don't have to understand what these algorithms are doing for now, just try and figure out their time complexities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is ok if you dont know the list creation line yet, but the list creation line by itself is O(N^2).\n",
    "def example1(adjmatrix, n, s, e):\n",
    "    distance = list(map(lambda i: list(map(lambda j: j, i)), adjmatrix)) \n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                distance[i][j] = min(distance[i][j], distance[i][k] + distance[k][j])\n",
    "    print(distance)\n",
    "\n",
    "# This one is not as simple as you may think, make sure to look at all of the lines of the function, and their \n",
    "# time complexities. \n",
    "def example2(n):\n",
    "    lt = [];\n",
    "    for i in range(n,0,-1):\n",
    "        lt.append(i)\n",
    "    lt.sort()\n",
    "    print(lt)\n",
    "\n",
    "# This is recursion which is extra hard because it doesn't have the regular for loop structure, you have to\n",
    "# create a recursive stack trace to figure this one out. \n",
    "def example3(x, n, m):\n",
    "    if (n == 0): return 1 % m\n",
    "    u = example3(x, n//2, m)\n",
    "    u = (u * u) % m\n",
    "    if (n % 2 == 1): u = (u * x) % m\n",
    "    return u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1 is $\\mathcal{O}(n^3)$. This is because the list creation section is $\\mathcal{O}(n^2)$ as given, the triple nested for loop is $\\mathcal{O}(n^3)$, and the print statement is $\\mathcal{O}(n^2)$. The most significant value out of the three parts is $\\mathcal{O}(n^3)$, so the overall time complexity of this algorithm is $\\mathcal{O}(n^3)$. This algorithm is actually called floyd-warshall, and its a graph theory algorithm. For more information come to one of our later lesson or look here https://www.geeksforgeeks.org/floyd-warshall-algorithm-dp-16/. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2 is $\\mathcal{O}(n\\log{n})$. This is because the list creation is $\\mathcal{O}(1)$, the for loop is $\\mathcal{O}(n)$, the sorting is $\\mathcal{O}(n\\log{n})$, and the print statement is $\\mathcal{O}(n)$. The most significant value out of the three parts is $\\mathcal{O}(n\\log{n})$, so the overall time complexity of this algorithm is $\\mathcal{O}(n\\log{n})$. This algorithm has no special name, it is just here to introduce the fact that the sort function that is included in the python library (and most other languages) is $\\mathcal{O}(n\\log{n})$. More information about the standard sort can be found here https://realpython.com/sorting-algorithms-python/#the-timsort-algorithm-in-python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3 is $\\mathcal{O}(\\log{n})$. This is because every line in the function is $\\mathcal{O}(1)$, so the overall function with one call is $\\mathcal{O}(1)$, but there are multiple recursive calls not only one. So in this case you have to multiply the number of recursive calls by the time complexity of one call. The function is dividing $n$ by two in every call, until n = 0, so there are $\\log_2{n}$ calls. $\\mathcal{O}(\\log{n}) \\cdot \\mathcal{O}(1) = \\mathcal{O}(\\log{n})$. This algorithm is called binary exponentiation, more information about it can be found here https://cp-algorithms.com/algebra/binary-exp.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space Complexity From Code \n",
    "\n",
    "Space complexity is very similar to finding time complexity, but instead of looking at for loops and other things that have known time complexities, you look at data structures with known space complexities. This process is illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function3(n):\n",
    "    lt = [];\n",
    "    for i in range(n):\n",
    "        lt.append(i)\n",
    "    print(lt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function3 only has one data structure that can be used for space complexities, lt. This list is appended to N times and each append has a space complexity of $\\mathcal{O}(1)$, so the total space complexity of this function is $\\mathcal{O}(n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function4(n): \n",
    "    lt = []\n",
    "    for i in range(n):\n",
    "        lt2 = []\n",
    "        for q in range(n):\n",
    "            lt2.append(q);\n",
    "        lt.append(lt2);\n",
    "    print(lt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function4 has two data structures that can be used for space complexities, lt and lt2. lt2 is appended to N times, and lt is appended to N times as well. However each append to lt has space complexity of $\\mathcal{O}(n)$ so the total space complexity of lt is $\\mathcal{O}(n^2)$. lt2 is appended to N times with each append having a space complexity of $\\mathcal{O}(1)$ so the total space complexity of lt2 is $\\mathcal{O}(n)$. The most significant space complexity is $\\mathcal{O}(n^2)$, so the total space of function4 is $\\mathcal{O}(n^2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all honesty, space complexity isn't as important as time complexity in most cases, as you are much more likely to go over time limits than to go over space limits. For that reason we are just going to reuse the examples for time complexity above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is ok if you dont know the list creation line yet, but the list creation line by itself is O(N^2) space.\n",
    "def example4(adjmatrix, n, s, e):\n",
    "    distance = list(map(lambda i: list(map(lambda j: j, i)), adjmatrix)) \n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                distance[i][j] = min(distance[i][j], distance[i][k] + distance[k][j])\n",
    "    print(distance)\n",
    "\n",
    "def example5(n):\n",
    "    lt = [];\n",
    "    for i in range(n,0,-1):\n",
    "        lt.append(i)\n",
    "    lt.sort()\n",
    "    print(lt)\n",
    "\n",
    "def example6(x, n, m):\n",
    "    if (n == 0): return 1 % m\n",
    "    u = example3(x, n//2, m)\n",
    "    u = (u * u) % m\n",
    "    if (n % 2 == 1): u = (u * x) % m\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 4 has a space complexity of $\\mathcal{O}(n^2)$. This is because the only data structure that exists is distance and we are given that distance is $\\mathcal{O}(n^2)$, so the total space complexity of the above function is $\\mathcal{O}(n^2)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 5 has a space complexity of $\\mathcal{O}(n)$. This is because the only data structure that exists is lt and we append to lt N times with a data structure of space complexity $\\mathcal{O}(1)$. $n \\cdot \\mathcal{O}(1) = \\mathcal{O}(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 6 has a space complexity of $\\mathcal{O}(1)$. This is because only integers are used are used in each recursive calls, and recursive calls are not run in unison, they are run one after another, so the overall space complexity is $\\mathcal{O}(1)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "If you are looking for a challenge to show your mastery of time and space complexities, go to https://visualgo.net/en/sorting and figure out the time and space complexities of all eight sorting algorithms from just the simulation and psuedocode given. The answers can be found here https://www.geeksforgeeks.org/analysis-of-different-sorting-techniques/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
